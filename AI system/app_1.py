import streamlit as st
import wandb
import base64
import pandas as pd
import matplotlib.pyplot as plt
from openai import OpenAI
from io import BytesIO

st.markdown("""
    <style>
    /* æ”¾å¤§ selectbox ä¸Šæ–¹æ¨™ç±¤çš„æ–‡å­— */
    div.stSelectbox label p {
        font-size: 26px !important;
        font-weight: 600 !important;
        color: #333333 !important;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown("<h1 style='margin-bottom: 30px;'>ğŸ” AI è¼”åŠ©è¨“ç·´çµæœè§£æç³»çµ±</h1>", unsafe_allow_html=True)

# éš±è—"press Enter to apply"
hide_submit_text = """
<style>
div[data-testid="InputInstructions"] > span:nth-child(1) {
    visibility: hidden;
}
</style>
"""
st.markdown(hide_submit_text, unsafe_allow_html=True)

# ---------------------- API è¨­å®š dialog -----------------------
@st.dialog("ğŸ” API é‡‘é‘°è¨­å®š", dismissible=False)
def api_keys_dialog(logged=False):
    openai_key = st.text_input(
        "OpenAI API Keyï¼š", type="password", value=st.session_state.get("openai_key", "")
    )
    wandb_key = st.text_input(
        "WandB API Keyï¼š", type="password", value=st.session_state.get("wandb_key", "")
    )
    
    if logged == True:
        col1, col2 = st.columns(2, vertical_alignment="bottom")
        button1 = col1.button("Login", width="stretch")
        button2 = col2.button("Cancel", width="stretch")
    else:
        button1 = st.button("Login", width="stretch")

    if button1:
        if not openai_key or not wandb_key:
            st.error("âŒ è«‹è¼¸å…¥å®Œæ•´ API é‡‘é‘°ï¼")
        
        elif wandb_key and len(wandb_key.strip()) != 40:
            st.warning(f"âš ï¸ ç›®å‰è¼¸å…¥é•·åº¦ç‚º {len(wandb_key.strip())}ï¼Œæ‡‰ç‚º 40 å­—å…ƒã€‚")
            
        else:
            st.session_state.openai_key = openai_key
            st.session_state.wandb_key = wandb_key

            # try:
                # ç¢ºèª api keys
            st.session_state.openai_logged = check_openai_key_valid(st.session_state.openai_key)
            st.session_state.wandb_logged = check_wandb_key_valid(st.session_state.wandb_key)

            if st.session_state.openai_logged and st.session_state.wandb_logged:
                st.session_state.api_verified = True
                st.rerun()
            else:
                st.error("âŒ ç„¡æ•ˆçš„ API é‡‘é‘°éŒ¯èª¤ï¼Œè«‹é‡æ–°ç¢ºèªï¼")
                print(st.session_state.openai_logged, st.session_state.wandb_logged)

    if logged == True:
        if button2:
            st.rerun()

# ------------- Get WanDB Project & Run data ------------------

def get_projects(api, entity):
    projects = api.projects(entity)
    return [p.name for p in projects]

def get_runs(api, entity, project_name):
    runs = api.runs(f"{entity}/{project_name}")
    return {r.displayName: r.id for r in runs}

def get_run_object(api, entity, project_name, run_id):
    return api.run(f"{entity}/{project_name}/{run_id}")

# ----------------- [UI] WanDB Project & Run -----------------

def get_project_run_selection(api, entity):
    project_names = get_projects(api, entity)
    runs_zip = []

    for p in project_names:
        runs_zip.append(get_runs(api, entity, p))

    return project_names, runs_zip


def validate_selection(project, run):
    if not project or not run:
        st.warning("âš ï¸ è«‹å…ˆé¸æ“‡å®Œæ•´çš„ Project èˆ‡ Run å†åŸ·è¡Œï¼")
        return False
    return True

# ------------- WanDB get traning datasets -----------------

def plot_wandb_history(history, target_cols, group_size=6):
    figures = []

    for i in range(0, len(target_cols), group_size):
        subset = target_cols[i:i + group_size]
        fig, axes = plt.subplots(2, 3, figsize=(15, 8))
        axes = axes.flatten()

        for j, col in enumerate(subset):
            ax = axes[j]
            ax.plot(history.index, history[col], label=col, linewidth=0.8)
            ax.set_xlabel("Step")
            ax.set_ylabel(col.split("/")[1])
            ax.set_title(col.split("/")[1])

        # é—œé–‰å¤šé¤˜çš„å­åœ–
        for k in range(len(subset), len(axes)):
            axes[k].axis("off")

        plt.tight_layout()
        figures.append(fig)

    return figures

# ------------------------- GPT å•ç­” ------------------------------

def analyze_plot_with_gpt(image_base64, client, user_query=None):
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # ç¬¬ä¸€æ¬¡: è‡ªå‹•åˆ†æè¨Šæ¯
    if user_query is None:
        user_msg = {
            "role": "user",
            "content": [
                {"type": "text",
                 "text": "è«‹åˆ†æé€™å¼µ Reward åœ–è¡¨çš„è¶¨å‹¢ï¼Œèªªæ˜è¨“ç·´éç¨‹ä¸­æ¨¡å‹çš„å­¸ç¿’ç‹€æ³èˆ‡å¯èƒ½çš„å•é¡Œã€‚"},
                {"type": "image_url",
                 "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
            ]
        }
    else:
        # å¾ŒçºŒæå•ï¼šä¸€èˆ¬ç´”æ–‡å­—è¨Šæ¯
        user_msg = {
            "role": "user",
            "content": [
                {"type": "text",
                 "text": user_query},
                {"type": "image_url",
                 "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
            ]
        }

    st.session_state.chat_history.append(user_msg)

    try:
        with st.spinner("GPT æ­£åœ¨æ€è€ƒ..."):
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=st.session_state.chat_history
            )

        assistant_reply = response.choices[0].message.content

        st.session_state.chat_history.append({
            "role": "assistant",
            "content": assistant_reply
        })

        return assistant_reply
    
    except Exception as e:
        st.error("âš ï¸ GPT åˆ†æå¤±æ•—ï¼Œè«‹æª¢æŸ¥ API æˆ–ç¶²è·¯é€£ç·š")
        return None
    
def display_chat(user_prompt, gpt_answer):
    if user_prompt != None:
        # Display user message in chat message container
        st.chat_message("user").markdown(user_prompt)
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": user_prompt})

    if gpt_answer != None:
        # Display assistant response in chat message container
        with st.chat_message("assistant"):
            st.markdown(gpt_answer)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": gpt_answer})


def check_openai_key_valid(api_key):
    try:
        client = OpenAI(api_key=api_key)
        _ = client.models.list()  # è¼•é‡ API è«‹æ±‚
        return True
    except Exception as e:
        print("OpenAI Key é©—è­‰å¤±æ•—ï¼š", e)
        return False

def check_wandb_key_valid(api_key):
    try:
        wandb.login(key=api_key)
        _ = wandb.Api()
        return True
    except Exception as e:
        print("WanDB Key é©—è­‰å¤±æ•—ï¼š", e)
        return False


# --------------------- Main -------------------------
def main():
    # ===== streamlit åƒæ•¸è¨­å®š =====
    ## ç‹€æ…‹åˆå§‹åŒ–
    if "api_verified" not in st.session_state:
        st.session_state.api_verified = False
    if "selectbox_modified" not in st.session_state:
        st.session_state.selectbox_modified = False

    ## API keys
    if "wandb_logged" not in st.session_state:
        st.session_state.wandb_logged = False
    if "openai_logged" not in st.session_state:
        st.session_state.openai_logged = False
    if "api" not in st.session_state:
        st.session_state.api = None
    if "client" not in st.session_state:
        st.session_state.client = None

    ## åœ–ç‰‡&å°è©±
    if "project_list" not in st.session_state:
        st.session_state.project_list = []
    if "runs_list" not in st.session_state:
        st.session_state.runs_list = []
    if "Graph_display" not in st.session_state:
        st.session_state.Graph_display = None    # AF:ä¸éœ€è¦é€™æ¨£å¯«
    if "Graph" not in st.session_state:
        st.session_state.Graph = None    # AF:ä¸éœ€è¦é€™æ¨£å¯«
    if "first_quest" not in st.session_state:
        st.session_state.first_quest = True

    # Initialize chat history
    if "messages" not in st.session_state:
      st.session_state.messages = []


    # === å›ºå®šå€å¡Š ===
    top_slot = st.container()      # ä¸Šæ–¹ï¼šé¸å–® + åœ–è¡¨


    # ===== dialog =====
    if not st.session_state.api_verified:
        api_keys_dialog()
        st.stop()

    if st.sidebar.button("âš™ï¸ è¨­å®š API"):
        api_keys_dialog(logged=True)
        st.stop()
    

    # ===== ç¢ºèª api keys =====
    ## OPENAI
    # st.session_state.openai_logged = check_openai_key_valid(st.session_state.openai_key)
    client = OpenAI(api_key=st.session_state.openai_key)

    ## WanDB
    # st.session_state.wandb_logged = check_wandb_key_valid(st.session_state.wandb_key)
    wandb.login(key=st.session_state.wandb_key)
    api = wandb.Api()
    entity = api.default_entity

    if len(st.session_state.project_list) == 0:
        st.session_state.project_list, st.session_state.runs_list = get_project_run_selection(api, entity)


    with top_slot:
        # ===== ä¸‹æ‹‰å¼é¸å–® =====
        col1, col2 = st.columns(2)

        with col1:
            selected_project = st.selectbox("ğŸ“ é¸æ“‡å°ˆæ¡ˆ (Project)ï¼š", st.session_state.project_list)

        with col2:
            if selected_project:
                runs = st.session_state.runs_list[st.session_state.project_list.index(selected_project)]
                selected_run = st.selectbox("ğŸ§ª é¸æ“‡å¯¦é©— (Run)ï¼š", runs.keys())
                if len(runs)>0:
                    selected_run = runs[selected_run]
            else:
                selected_run = None

        button_showGrpah = st.button("ğŸš€ Show Graph")
        
        divide = st.empty()    # åˆ†éš”ç·š
        Graph = st.empty()
        if st.session_state.Graph_display is not None:
            divide.divider()    # åˆ†éš”ç·š
            Graph.pyplot(st.session_state.Graph_display, width="content")


        # ===== å¾WanDBè³‡æ–™ç”¢ç”Ÿåœ–ç‰‡
        if button_showGrpah:
            if validate_selection(selected_project, selected_run):
                run = get_run_object(api, entity, selected_project, selected_run)
                # st.success(f"âœ… å·²æˆåŠŸè¼‰å…¥ Runï¼š{run.name}")
                divide.divider()    # åˆ†éš”ç·š
                
                # è£½åœ–
                with st.spinner("æ ¹æ“š Reward Data ç”ŸæˆæŠ˜ç·šåœ–..."):
                    history = run.history(samples=10000)
                    target_cols = [
                        col for col in history.columns
                        if pd.api.types.is_numeric_dtype(history[col]) and col.split("/")[0] == "Episode_Reward"
                    ]
                    figures = plot_wandb_history(history, target_cols)

                # å­˜åœ–å†è®€
                fig = figures[0]
                buf = BytesIO()
                fig.savefig(buf, format="png")
                buf.seek(0)
                image_base64 = base64.b64encode(buf.getvalue()).decode("utf-8")

                # é¡¯ç¤ºåœ–è¡¨
                st.session_state.Graph_display = fig
                Graph.pyplot(st.session_state.Graph_display, width="content")
                # st.chat_message("user").markdown(fig)   # ä¸èƒ½é€™æ¨£ç”¨

                st.session_state.Graph = image_base64
                plt.close(fig)

            else:
                st.session_state.Graph = None
                st.stop()
    

    st.divider()
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ç¬¬ä¸€æ¬¡è‡ªå‹•è©¢å• GPT ä¸¦é¡¯ç¤ºå›è¦†
    if st.session_state.first_quest and st.session_state.Graph is not None:
        gpt_answer = analyze_plot_with_gpt(st.session_state.Graph, client)
        with st.chat_message("assistant"):
            st.markdown(gpt_answer)
        st.session_state.messages.append({"role": "assistant", "content": gpt_answer})
        st.session_state.first_quest = False

    # å¾ŒçºŒç”±ä½¿ç”¨è€…è¼¸å…¥æå•
    if not st.session_state.first_quest:
        if user_prompt := st.chat_input("æ ¹æ“šé€™å¼µåœ–å…¶ä»–å•é¡Œï¼Ÿ"):
            gpt_answer = analyze_plot_with_gpt(st.session_state.Graph, client, user_prompt)
            with st.chat_message("user"):
                st.markdown(user_prompt)
            st.session_state.messages.append({"role": "user", "content": user_prompt})
            with st.chat_message("assistant"):
                st.markdown(gpt_answer)
            st.session_state.messages.append({"role": "assistant", "content": gpt_answer})

if __name__ == "__main__":
    main()
